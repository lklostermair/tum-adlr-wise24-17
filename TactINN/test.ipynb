{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[138], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m project_root \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18;43m__file__\u001b[39;49m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m project_root \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mpath:\n\u001b[1;32m      5\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(project_root)\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import FrEIA.framework as Ff\n",
    "import FrEIA.modules as Fm\n",
    "import h5py\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import TactileMaterialDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    A small MLP that takes in half of the data (and possibly label embedding)\n",
    "    and outputs scale + shift parameters for an affine coupling.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, hidden_dim=128, out_channels=16, label_dim=0):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        # If using label embeddings, add label_dim to input\n",
    "        self.fc1 = nn.Linear(in_channels + label_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, out_channels * 2)  # scale & shift\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        # x shape: (batch_size, in_channels)\n",
    "        if y is not None:\n",
    "            # Concatenate label embedding to input\n",
    "            x = torch.cat([x, y], dim=1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        # Return scale & shift\n",
    "        scale, shift = torch.chunk(x, 2, dim=1)\n",
    "        return scale, shift\n",
    "\n",
    "class SimpleCNN1D(nn.Module):\n",
    "    \"\"\"\n",
    "    A small 1D CNN that takes in half of the data (and possibly label embedding)\n",
    "    and outputs scale + shift parameters for an affine coupling.\n",
    "    \n",
    "    :param in_channels: Number of input features for half of the data. \n",
    "                        (If you split the data in half, this is the size of x1 or x2.)\n",
    "    :param hidden_channels: Number of output channels in the hidden convolution layers.\n",
    "    :param kernel_size: Size of the convolution kernel.\n",
    "    :param out_channels: Final dimension for scale/shift (usually equals half-split size).\n",
    "    :param label_dim: Embedding dimension for the label (if using class-conditional flow).\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 hidden_channels=32,\n",
    "                 kernel_size=3,\n",
    "                 out_channels=16,\n",
    "                 label_dim=0):\n",
    "        super(SimpleCNN1D, self).__init__()\n",
    "        self.label_dim = label_dim\n",
    "        self.in_channels = in_channels  # The \"width\" for 1D conv if we treat it as (batch, 1, in_channels)\n",
    "\n",
    "        # First 1D conv layer\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=1,\n",
    "            out_channels=hidden_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=kernel_size // 2\n",
    "        )\n",
    "        \n",
    "        # Second 1D conv layer\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=hidden_channels,\n",
    "            out_channels=hidden_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=kernel_size // 2\n",
    "        )\n",
    "        \n",
    "        # Non-linear activation\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # After two conv layers, the shape is (batch_size, hidden_channels, in_channels).\n",
    "        # We'll flatten this to (batch_size, hidden_channels * in_channels).\n",
    "        self.flatten_dim = hidden_channels * in_channels\n",
    "        \n",
    "        # Final linear layer outputs 2*out_channels (scale + shift)\n",
    "        # We add label_dim if using conditional embeddings\n",
    "        print(f\"DEBUG: self.flatten_dim = {self.flatten_dim}, label_dim = {label_dim}, total_in_features = {self.flatten_dim + label_dim}\")\n",
    "\n",
    "        self.fc_out = nn.Linear(self.flatten_dim + label_dim, out_channels * 2)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        \"\"\"\n",
    "        :param x: Tensor of shape (batch_size, in_channels)\n",
    "        :param y: Optional label embedding of shape (batch_size, label_dim)\n",
    "        :return: (scale, shift) each of shape (batch_size, out_channels)\n",
    "        \"\"\"\n",
    "        # Reshape to (batch_size, 1, in_channels) for 1D convolution\n",
    "        x = x.unsqueeze(1)  # now shape = (batch_size, 1, in_channels)\n",
    "        \n",
    "        # Pass through 1D convolutions\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # Flatten to (batch_size, hidden_channels * in_channels)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # If labels provided, concatenate\n",
    "        if y is not None:\n",
    "            x = torch.cat([x, y], dim=1)\n",
    "        \n",
    "        # Final linear layer produces (scale, shift)\n",
    "        x = self.fc_out(x)\n",
    "        scale, shift = torch.chunk(x, 2, dim=1)\n",
    "        \n",
    "        return scale, shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def affine_coupling_block(in_dim, label_dim=0, hidden_dim=128, subnet_type='cnn'):\n",
    "    \"\"\"\n",
    "    Create an invertible affine coupling block for 1D data.\n",
    "    We treat the entire feature dimension as one \"channel\".\n",
    "    \"\"\"\n",
    "    print(\"DEBUG: affine_coupling_block in_dim =\", in_dim)\n",
    "    # The CouplingBlock in FrEIA needs a callable that produces the scale/shift.\n",
    "    # We pass in a lambda that calls our MLP with the correct shapes.\n",
    "    def subnet_constructor(c_in, c_out):\n",
    "        # c_in is the size of the partition of data passed into the subnet\n",
    "        # c_out is the number of parameters to predict (scale+shift)\n",
    "        if subnet_type == 'mlp':\n",
    "            return SimpleMLP(c_in, hidden_dim, c_out // 2, label_dim=label_dim)\n",
    "        elif subnet_type == 'cnn':\n",
    "            return SimpleCNN1D(c_in, hidden_dim, out_channels=c_out // 2, label_dim=label_dim)\n",
    "\n",
    "\n",
    "    # We use the AffineCouplingOneSided with a custom subnet\n",
    "    coupling = Fm.AllInOneBlock(\n",
    "        dims_in = [(in_dim,)],\n",
    "        subnet_constructor = subnet_constructor,\n",
    "        affine_clamping = 2.0,  # stability parameter\n",
    "        permute_soft = False,    # whether to permute inside the block\n",
    "    )\n",
    "    return coupling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InvertibleFlow(nn.Module):\n",
    "    def __init__(self, data_dim=16000, n_blocks=6, label_dim=0, hidden_dim=128):\n",
    "        \"\"\"\n",
    "        data_dim: dimension of your flattened data, e.g. 1000*16=16000\n",
    "        n_blocks: how many coupling blocks\n",
    "        label_dim: dimension of label embedding\n",
    "        hidden_dim: size of hidden layers in subnets\n",
    "        \"\"\"\n",
    "        super(InvertibleFlow, self).__init__()\n",
    "        self.data_dim = data_dim\n",
    "        self.n_blocks = n_blocks\n",
    "        self.label_dim = label_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        print(\"DEBUG: InvertibleFlow.__init__: self.data_dim =\", self.data_dim)\n",
    "        print(\"DEBUG: InvertibleFlow.__init__: self.label_dim =\", self.label_dim)        \n",
    "        print(\"DEBUG: InvertibleFlow.__init__: self.hidden_dim =\", self.hidden_dim)\n",
    "        \n",
    "\n",
    "        # Build the computation graph\n",
    "        self.flow = Ff.SequenceINN(data_dim)\n",
    "\n",
    "        for k in range(self.n_blocks):\n",
    "            self.flow.append(Fm.PermuteRandom(dims_in=[(self.data_dim,)], seed=k))\n",
    "            # Add the coupling block\n",
    "            self.flow.append(\n",
    "                affine_coupling_block(in_dim=self.data_dim,\n",
    "                                      label_dim=label_dim,\n",
    "                                      hidden_dim=hidden_dim)\n",
    "            )\n",
    "\n",
    "        # Embedding for labels (optional)\n",
    "        if self.label_dim > 0:\n",
    "            self.label_embedding = nn.Embedding(num_embeddings=36, embedding_dim=label_dim)\n",
    "        else:\n",
    "            self.label_embedding = None\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        \"\"\"\n",
    "        Forward pass: x -> z\n",
    "        x shape: (batch_size, data_dim)\n",
    "        labels shape: (batch_size,)  # integer class labels\n",
    "        \"\"\"\n",
    "        # Optionally get label embeddings\n",
    "        if self.label_embedding is not None and labels is not None:\n",
    "            y_emb = self.label_embedding(labels)\n",
    "        else:\n",
    "            y_emb = None\n",
    "\n",
    "        # forward pass: returns z, log_detJ\n",
    "        z, log_detJ = self.flow(x, c=y_emb)\n",
    "        return z, log_detJ\n",
    "\n",
    "    def inverse(self, z, labels=None):\n",
    "        \"\"\"\n",
    "        Inverse pass: z -> x\n",
    "        z shape: (batch_size, data_dim)\n",
    "        \"\"\"\n",
    "        if self.label_embedding is not None and labels is not None:\n",
    "            y_emb = self.label_embedding(labels)\n",
    "        else:\n",
    "            y_emb = None\n",
    "\n",
    "        x, log_detJ = self.flow.inverse(z, c=y_emb)\n",
    "        return x, log_detJ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassConditionalGMM(nn.Module):\n",
    "    \"\"\"\n",
    "    Holds parameters (mu_c, logvar_c) for each class c, \n",
    "    representing a Gaussian in the latent space.\n",
    "    For simplicity, we assume diagonal covariance.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_classes, latent_dim):\n",
    "        super().__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Each class has its own mean and log-variance (diagonal covariance)\n",
    "        self.mu = nn.Parameter(torch.zeros(n_classes, latent_dim))\n",
    "        self.logvar = nn.Parameter(torch.zeros(n_classes, latent_dim))\n",
    "    \n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Returns log p_Z(z|c) for each class c, in a (batch_size, n_classes) tensor.\n",
    "        \n",
    "        :param z: (batch_size, latent_dim)\n",
    "        :return: log_probs: shape (batch_size, n_classes)\n",
    "                 where log_probs[i, c] = log p_Z(z[i]|c).\n",
    "        \"\"\"\n",
    "        # Expand z to shape (batch_size, 1, latent_dim)\n",
    "        # so we can broadcast with (n_classes, latent_dim)\n",
    "        z_expanded = z.unsqueeze(dim=1)  # (batch_size, 1, latent_dim)\n",
    "        \n",
    "        # shape of mu: (n_classes, latent_dim)\n",
    "        # shape of logvar: (n_classes, latent_dim)\n",
    "        mu = self.mu.unsqueeze(dim=0)         # -> (1, n_classes, latent_dim)\n",
    "        logvar = self.logvar.unsqueeze(dim=0) # -> (1, n_classes, latent_dim)\n",
    "        \n",
    "        # Compute negative Mahalanobis (for diagonal covariance):\n",
    "        # (z - mu)^2 / exp(logvar)\n",
    "        # We'll do this per class c:\n",
    "        neg_mahalanobis = -0.5 * torch.sum((z_expanded - mu)**2 / torch.exp(logvar), dim=2)\n",
    "        \n",
    "        # Also subtract the normalization term: (1/2) * sum(logvar) + (D/2)*log(2*pi)\n",
    "        # D = latent_dim\n",
    "        D = self.latent_dim\n",
    "        log_det = -0.5 * torch.sum(logvar, dim=2)  # shape (1, n_classes)\n",
    "        \n",
    "        # Constant term: (D/2)*log(2*pi)\n",
    "        const = -0.5 * D * torch.log(torch.tensor([2.0 * 3.1415926535], device=z.device))\n",
    "        \n",
    "        log_probs = neg_mahalanobis + log_det + const  # shape (batch_size, n_classes)\n",
    "        \n",
    "        return log_probs\n",
    "\n",
    "def combined_loss(x, c, model, gmm, beta=1.0):\n",
    "    \"\"\"\n",
    "    :param x: (batch_size, data_dim) input data\n",
    "    :param c: (batch_size,) class labels (integers 0..n_classes-1)\n",
    "    :param model: your invertible flow model, where model(x) -> (z, log_detJ)\n",
    "    :param gmm: ClassConditionalGMM instance\n",
    "    :param beta: weighting factor for classification term\n",
    "    :return: total_loss, generative_loss, classification_loss\n",
    "    \"\"\"\n",
    "    # 1) Forward pass through the flow: x -> z\n",
    "    z, log_detJ = model(x)  # (batch_size, latent_dim), (batch_size,)\n",
    "    \n",
    "    # 2) Generative Loss\n",
    "    # We assume standard Gaussian p_Z(z) for L_generative \n",
    "    # or you can do class-unconditional p_Z(z) = Normal(0, I)\n",
    "    log_pz = -0.5 * (z**2).sum(dim=1)  # ignoring constant\n",
    "    L_generative = -(log_pz + log_detJ).mean()\n",
    "    \n",
    "    # 3) Classification Loss (via GMM log-likelihood for each class)\n",
    "    # We compute log p_Z(z|c) for all classes, then do cross-entropy w.r.t. the true class.\n",
    "    all_class_log_probs = gmm(z)  # shape (batch_size, n_classes)\n",
    "    # We want - sum_{c} y_c log p_Z(z|c). \n",
    "    # If c is the true class, the cross-entropy style approach is:\n",
    "    \n",
    "    # classification loss: cross_entropy( log_probs, c )\n",
    "    # BUT we have log p_Z(z|c) in 'all_class_log_probs'. \n",
    "    # We can use PyTorch's log_softmax -> cross_entropy trick:\n",
    "    # cross_entropy( log_softmax(all_class_log_probs), c )\n",
    "    \n",
    "    # But note: all_class_log_probs is already in \"log space\" but not necessarily normalized.\n",
    "    # We can directly call: F.nll_loss( log_softmax(all_class_log_probs, dim=1 ), c )\n",
    "    log_probs_normed = Ff.log_softmax(all_class_log_probs, dim=1)  # shape (batch_size, n_classes)\n",
    "    \n",
    "    # Negative log-likelihood for the correct class\n",
    "    L_classification = Ff.nll_loss(log_probs_normed, c)\n",
    "    \n",
    "    # 4) Total Loss\n",
    "    total_loss = L_generative + beta * L_classification\n",
    "    \n",
    "    return total_loss, L_generative.detach(), L_classification.detach()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TactileDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset for loading tactmat.h5 data (36 materials, \n",
    "    each with 100 samples). It flattens the 4x4 grid into 16 features \n",
    "    per timestep, optionally flattens time dimension as well.\n",
    "    \"\"\"\n",
    "    def __init__(self, h5_filename, flatten_time_feature=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load HDF5\n",
    "        with h5py.File(h5_filename, 'r') as hf:\n",
    "            # Check datasets\n",
    "            if 'materials' not in hf:\n",
    "                raise KeyError(\"Dataset '/materials' not found in the HDF5 file.\")\n",
    "            if 'samples' not in hf:\n",
    "                raise KeyError(\"Dataset '/samples' not found in the HDF5 file.\")\n",
    "\n",
    "            # Materials: shape (36,) dtype string\n",
    "            materials_data = hf['materials'][:]\n",
    "            self.materials = [m.decode('utf-8') for m in materials_data]\n",
    "\n",
    "            # Samples: shape (36, 100, 1000, 4, 4), dtype int64\n",
    "            samples_data = hf['samples'][:]  # shape (36, 100, 1000, 4, 4)\n",
    "\n",
    "        # Flatten 4x4 -> 16\n",
    "        samples_data = samples_data.reshape(36, 100, 1000, 16)\n",
    "        \n",
    "        # We now have shape (36, 100, 1000, 16).\n",
    "        # We'll store them in a list of shape (36, 100, 1000, 16).\n",
    "        self.num_materials = 36\n",
    "        self.samples_per_material = 100\n",
    "        \n",
    "        self.flatten_time_feature = flatten_time_feature\n",
    "\n",
    "        # We'll create a big list of length 3600 (36*100),\n",
    "        # but we'll keep track of which material each sample belongs to.\n",
    "        self.data_list = []\n",
    "        self.label_list = []\n",
    "        \n",
    "        for mat_idx in range(self.num_materials):\n",
    "            for sample_idx in range(self.samples_per_material):\n",
    "                sample_3d = samples_data[mat_idx, sample_idx]  # shape (1000, 16)\n",
    "                if self.flatten_time_feature:\n",
    "                    # shape -> (1000*16,) = (16000,)\n",
    "                    sample_3d = sample_3d.reshape(-1)\n",
    "                self.data_list.append(sample_3d)\n",
    "                self.label_list.append(mat_idx)\n",
    "        \n",
    "        # Convert to Torch Tensors\n",
    "        self.data_list = torch.tensor(np.array(self.data_list), dtype=torch.float32)\n",
    "        self.label_list = torch.tensor(self.label_list, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)  # 36 * 100 = 3600\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_list[idx], self.label_list[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_material(dataset, train_count=80, val_count=20):\n",
    "    \"\"\"\n",
    "    Given the TactileDataset, produce train/val Subsets:\n",
    "    For each material's block of 100 samples:\n",
    "      - first 'train_count' go to train\n",
    "      - next 'val_count' go to val\n",
    "    \n",
    "    This yields total train=36*80=2880, val=36*20=720\n",
    "    \"\"\"\n",
    "    indices_train = []\n",
    "    indices_val = []\n",
    "    \n",
    "    # Each material has 100 samples, in a contiguous block if we appended them in order.\n",
    "    # The dataset has them in the order: material 0: 100 samples, material 1: 100 samples, ...\n",
    "    # So for material i, the block is: [i*100, i*100+1, ..., i*100+99]\n",
    "    \n",
    "    for mat_idx in range(dataset.num_materials):\n",
    "        start = mat_idx * dataset.samples_per_material\n",
    "        train_inds = range(start, start + train_count)\n",
    "        val_inds = range(start + train_count, start + train_count + val_count)\n",
    "        \n",
    "        indices_train.extend(train_inds)\n",
    "        indices_val.extend(val_inds)\n",
    "    \n",
    "    # Create Subsets\n",
    "    from torch.utils.data import Subset\n",
    "    train_subset = Subset(dataset, indices_train)\n",
    "    val_subset = Subset(dataset, indices_val)\n",
    "    return train_subset, val_subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: InvertibleFlow.__init__: self.data_dim = 16000\n",
      "DEBUG: InvertibleFlow.__init__: self.label_dim = 8\n",
      "DEBUG: InvertibleFlow.__init__: self.hidden_dim = 128\n",
      "DEBUG: affine_coupling_block in_dim = 16000\n",
      "DEBUG: self.flatten_dim = 1024000, label_dim = 8, total_in_features = 1024008\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:117] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 65536512000 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[135], line 152\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Val   Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_val_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m     \u001b[43mtrain_inn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mh5_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/luki/tum-adlr-wise24-17/data/raw/tactmat.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_blocks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnoise_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# define the noise amount\u001b[39;49;00m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[135], line 41\u001b[0m, in \u001b[0;36mtrain_inn\u001b[0;34m(h5_filename, epochs, batch_size, beta, label_dim, hidden_dim, n_blocks, lr, augment, noise_level, patience)\u001b[0m\n\u001b[1;32m     38\u001b[0m data_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16000\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# 2) Build Model and GMM\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m flow_model \u001b[38;5;241m=\u001b[39m \u001b[43mInvertibleFlow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_blocks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_blocks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# embed the labels\u001b[39;49;00m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_dim\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m gmm \u001b[38;5;241m=\u001b[39m ClassConditionalGMM(n_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m36\u001b[39m, latent_dim\u001b[38;5;241m=\u001b[39mdata_dim)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# 3) Optimizer + Scheduler\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[130], line 27\u001b[0m, in \u001b[0;36mInvertibleFlow.__init__\u001b[0;34m(self, data_dim, n_blocks, label_dim, hidden_dim)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflow\u001b[38;5;241m.\u001b[39mappend(Fm\u001b[38;5;241m.\u001b[39mPermuteRandom(dims_in\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dim,)], seed\u001b[38;5;241m=\u001b[39mk))\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Add the coupling block\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflow\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m---> 27\u001b[0m         \u001b[43maffine_coupling_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mlabel_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Embedding for labels (optional)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_dim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[129], line 19\u001b[0m, in \u001b[0;36maffine_coupling_block\u001b[0;34m(in_dim, label_dim, hidden_dim, subnet_type)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m SimpleCNN1D(c_in, hidden_dim, out_channels\u001b[38;5;241m=\u001b[39mc_out \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, label_dim\u001b[38;5;241m=\u001b[39mlabel_dim)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# We use the AffineCouplingOneSided with a custom subnet\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m coupling \u001b[38;5;241m=\u001b[39m \u001b[43mFm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAllInOneBlock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdims_in\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubnet_constructor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msubnet_constructor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43maffine_clamping\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# stability parameter\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpermute_soft\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# whether to permute inside the block\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m coupling\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/FrEIA/modules/all_in_one_block.py:171\u001b[0m, in \u001b[0;36mAllInOneBlock.__init__\u001b[0;34m(self, dims_in, dims_c, subnet_constructor, affine_clamping, gin_block, global_affine_init, global_affine_type, permute_soft, learned_householder_permutation, reverse_permutation)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m subnet_constructor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease supply a callable subnet_constructor \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction or object (see docstring)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubnet \u001b[38;5;241m=\u001b[39m \u001b[43msubnet_constructor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplits\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcondition_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplits\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_jac \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[129], line 15\u001b[0m, in \u001b[0;36maffine_coupling_block.<locals>.subnet_constructor\u001b[0;34m(c_in, c_out)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SimpleMLP(c_in, hidden_dim, c_out \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, label_dim\u001b[38;5;241m=\u001b[39mlabel_dim)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m subnet_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcnn\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSimpleCNN1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc_out\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[128], line 78\u001b[0m, in \u001b[0;36mSimpleCNN1D.__init__\u001b[0;34m(self, in_channels, hidden_channels, kernel_size, out_channels, label_dim)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Final linear layer outputs 2*out_channels (scale + shift)\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# We add label_dim if using conditional embeddings\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEBUG: self.flatten_dim = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, label_dim = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, total_in_features = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten_dim\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39mlabel_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_out \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabel_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.12/site-packages/torch/nn/modules/linear.py:106\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_features \u001b[38;5;241m=\u001b[39m in_features\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features \u001b[38;5;241m=\u001b[39m out_features\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(\n\u001b[0;32m--> 106\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m )\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(out_features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:117] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 65536512000 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "def train_inn(\n",
    "    h5_filename=\"/home/luki/tum-adlr-wise24-17/data/raw/tactmat.h5\",\n",
    "    epochs=5,\n",
    "    batch_size=16,\n",
    "    beta=1.0,\n",
    "    label_dim=8,\n",
    "    hidden_dim=128,\n",
    "    n_blocks=6,\n",
    "    lr=1e-4,\n",
    "    augment=True,\n",
    "    noise_level=0.01,  # <--- define a default noise_level\n",
    "    patience=5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the InvertibleFlow + ClassConditionalGMM on \n",
    "    a train/val split. Evaluate classification accuracy on val.\n",
    "    \n",
    "    :param h5_filename: Path to the HDF5 file.\n",
    "    :param epochs: Number of training epochs.\n",
    "    :param batch_size: Batch size for both train and val.\n",
    "    :param beta: Weight factor for classification term in combined loss.\n",
    "    :param label_dim: Embedding dimension for label embedding in the flow.\n",
    "    :param hidden_dim: Hidden dimension for the coupling block subnets.\n",
    "    :param n_blocks: Number of coupling blocks in the flow.\n",
    "    :param lr: Learning rate for the optimizer.\n",
    "    :param augment: Whether to add noise-based data augmentation.\n",
    "    :param noise_level: Amount of Gaussian noise to add if augment=True.\n",
    "    :param patience: Patience epochs for early stopping.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Load Dataset\n",
    "    train_dataset = TactileMaterialDataset(h5_filename, split='train')\n",
    "    val_dataset = TactileMaterialDataset(h5_filename, split='val')\n",
    "\n",
    "    # 2) Prepare DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Debugging\n",
    "    print(f\"Train loader size: {len(train_loader.dataset)}\")\n",
    "    print(f\"Validation loader size: {len(val_loader.dataset)}\")\n",
    "\n",
    "    # 3) Initialize Model and Components\n",
    "    data_dim = train_dataset.data.size(-1)  # Infer data_dim from dataset\n",
    "    flow_model = InvertibleFlow(data_dim=data_dim, n_blocks=n_blocks, label_dim=label_dim, hidden_dim=hidden_dim)\n",
    "    gmm = ClassConditionalGMM(n_classes=36, latent_dim=data_dim)\n",
    "\n",
    "    # Optimizer\n",
    "    params = list(flow_model.parameters()) + list(gmm.parameters())\n",
    "    optimizer = torch.optim.Adam(params, lr=lr, weight_decay=1e-5)\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "\n",
    "    # Training and validation loop\n",
    "    best_val_loss = float('inf')\n",
    "    wait = 0\n",
    "\n",
    "    # 5) Training Loop\n",
    "    for epoch in range(epochs):\n",
    "        flow_model.train()\n",
    "        gmm.train()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        total_gen_loss = 0.0\n",
    "        total_cls_loss = 0.0\n",
    "        total_samples = 0\n",
    "        \n",
    "        # 5A) Training Phase\n",
    "        for x_batch, c_batch in train_loader:\n",
    "            if augment:\n",
    "                x_batch = x_batch + noise_level * torch.randn_like(x_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward + combined loss\n",
    "            loss, l_gen, l_cls = combined_loss(\n",
    "                x_batch, c_batch,\n",
    "                model=flow_model,\n",
    "                gmm=gmm,\n",
    "                beta=beta\n",
    "            )\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(flow_model.parameters(), max_norm=5.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_size_now = x_batch.size(0)\n",
    "            total_samples += batch_size_now\n",
    "            total_loss += loss.item() * batch_size_now\n",
    "            total_gen_loss += l_gen.item() * batch_size_now\n",
    "            total_cls_loss += l_cls.item() * batch_size_now\n",
    "        \n",
    "        # Average training losses\n",
    "        avg_train_loss = total_loss / total_samples\n",
    "        avg_train_gen_loss = total_gen_loss / total_samples\n",
    "        avg_train_cls_loss = total_cls_loss / total_samples\n",
    "        \n",
    "        # 5B) Validation Phase\n",
    "        flow_model.eval()\n",
    "        gmm.eval()\n",
    "        \n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_loss_sum = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x_val, c_val in val_loader:\n",
    "                # Evaluate combined loss for validation\n",
    "                v_loss, _, _ = combined_loss(\n",
    "                    x_val, c_val,\n",
    "                    model=flow_model,\n",
    "                    gmm=gmm,\n",
    "                    beta=beta\n",
    "                )\n",
    "                val_loss_sum += v_loss.item() * x_val.size(0)\n",
    "                val_total += x_val.size(0)\n",
    "\n",
    "                # Classification accuracy\n",
    "                z_val, _ = flow_model(x_val, labels=c_val)\n",
    "                all_class_log_probs = gmm(z_val)\n",
    "                pred_c = torch.argmax(all_class_log_probs, dim=1)\n",
    "                \n",
    "                val_correct += (pred_c == c_val).sum().item()\n",
    "        \n",
    "        avg_val_loss = val_loss_sum / val_total\n",
    "        val_accuracy = val_correct / val_total\n",
    "        \n",
    "        # 5C) Scheduler step\n",
    "        scheduler.step()\n",
    "\n",
    "        # 5D) Early Stopping Check \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            wait = 0\n",
    "            # Optionally save the best model here\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "        \n",
    "        # 5E) Print epoch summary\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "        print(f\"  Train Loss: {avg_train_loss:.4f} (Gen: {avg_train_gen_loss:.4f}, Cls: {avg_train_cls_loss:.4f})\")\n",
    "        print(f\"  Val   Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    train_inn(\n",
    "        h5_filename=\"/home/luki/tum-adlr-wise24-17/data/raw/tactmat.h5\",\n",
    "        epochs=5,\n",
    "        batch_size=16,\n",
    "        beta=1.0,\n",
    "        label_dim=8,\n",
    "        hidden_dim=128,\n",
    "        n_blocks=6,\n",
    "        lr=1e-4,\n",
    "        augment=True,\n",
    "        noise_level=0.01,  # define the noise amount\n",
    "        patience=5,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
